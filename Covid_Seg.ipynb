{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Covid_Seg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ADiko1997/DotNet/blob/master/Covid_Seg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIlSpqsaMofG",
        "outputId": "552e3136-d237-4cd6-a9d7-318b52054296"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tP-lhHVSr1nu"
      },
      "source": [
        "from PIL import Image\n",
        "import PIL\n",
        "import os\n",
        "import torchvision.utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import ImageFile\n",
        "from PIL import Image\n",
        "import random\n",
        "import dataclasses\n",
        "from dataclasses import dataclass\n",
        "from dataclasses import asdict\n",
        "from sklearn.metrics import f1_score, roc_curve, accuracy_score, auc\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import math\n",
        "import cv2\n",
        "from IPython.display import Image\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms.functional as TF\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WAi-G3xATknw",
        "outputId": "eff7d64d-f417-4804-f089-9bfe5469e5ba"
      },
      "source": [
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc935d91ca8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c7TwZ_gAyhfK"
      },
      "source": [
        "#@title PATHS \n",
        "train_img = \"/content/train\"\n",
        "train_masks = \"/content/train_labels\"\n",
        "test_img = \"/content/test\"\n",
        "test_maska = \"/content/test_labels\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "De2mk59BGt-5"
      },
      "source": [
        "#Parameters \n",
        "@dataclass\n",
        "class Config:\n",
        " \n",
        " \n",
        "    n_epochs: int = 100  # number of epochs of training\n",
        "    decay_epoch: int = 5  # epoch from which to start lr decay\n",
        " \n",
        "    img_height: int = 512  # size of image height # default 256x256\n",
        "    img_width: int = 512  # size of image width\n",
        " \n",
        "    batch_size: int = 4 # size of the batches\n",
        "    lr: float = 0.01  # adam: learning rate\n",
        "    b1: float = 0.5  # adam: decay of first order momentum of gradient\n",
        " \n",
        "    channels: int = 3  # number of image channels\n",
        "    n_cpu: int = 4  # number of cpu threads to use for the dataloaders\n",
        "    moemntum: int = 0.9\n",
        " \n",
        " \n",
        "cfg = Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7O6tOKcBsJrv",
        "outputId": "bf76e643-9d5e-4a29-d99a-3f1c85a0f8c7"
      },
      "source": [
        "!wget http://ncov-ai.big.ac.cn/download/ct_lesion_seg.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-24 17:13:30--  http://ncov-ai.big.ac.cn/download/ct_lesion_seg.zip\n",
            "Resolving ncov-ai.big.ac.cn (ncov-ai.big.ac.cn)... 124.16.164.43\n",
            "Connecting to ncov-ai.big.ac.cn (ncov-ai.big.ac.cn)|124.16.164.43|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 \n",
            "Length: 884253723 (843M) [application/octet-stream]\n",
            "Saving to: ‘ct_lesion_seg.zip.1’\n",
            "\n",
            "ct_lesion_seg.zip.1 100%[===================>] 843.29M  3.64MB/s    in 2m 36s  \n",
            "\n",
            "2020-11-24 17:16:08 (5.40 MB/s) - ‘ct_lesion_seg.zip.1’ saved [884253723/884253723]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EZboGro6uaVg"
      },
      "source": [
        "!unzip ct_lesion_seg.zip >> out.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G8mlj_A_sJy1"
      },
      "source": [
        "#@title splitting data\n",
        " \n",
        "import shutil\n",
        " \n",
        "home = os.getcwd()\n",
        "N_patient = os.listdir(home + \"/ct_lesion_seg/mask\")\n",
        "index =0\n",
        "for i in range(len(N_patient)):\n",
        "    if N_patient[i] == \".DS_Store\":\n",
        "      # print(i)\n",
        "      index = i\n",
        " \n",
        "N_patient.pop(index)\n",
        " \n",
        "# for i in range(len(N_patient)):\n",
        "#     print(N_patient[i],\"index \",i)          #creo lista con file dentro$\n",
        "#del N_patient[0]                                      #rimuovo Ds_store dala lista\n",
        "random.shuffle(N_patient)                             #dispone in modo casuale i pazienti$\n",
        "  \n",
        "    \n",
        "newpath = home + '/test'\n",
        "if not os.path.exists(newpath):                     #crea la cartella test\n",
        "    os.mkdir(newpath)\n",
        " \n",
        "newpath = home + '/test_labels'\n",
        "if not os.path.exists(newpath):\n",
        "    os.mkdir(newpath)\n",
        "    \n",
        "newpath = home + '/train'\n",
        "if not os.path.exists(newpath):                     #crea la cartella train\n",
        "    os.mkdir(newpath)\n",
        " \n",
        "newpath = home + '/train_labels'\n",
        "if not os.path.exists(newpath):\n",
        "    os.mkdir(newpath)\n",
        "   \n",
        "base_dir = home + '/ct_lesion_seg/mask'                   #definisco due variabili base_d$\n",
        "base_dir1 = home + '/ct_lesion_seg/image'\n",
        " \n",
        " \n",
        " \n",
        "for i in range(0,120):\n",
        "    N_slice=os.listdir(home+\"/ct_lesion_seg/mask/\"+N_patient[i])              \n",
        "    for j in range(0,len(N_slice)):\n",
        "        Name=N_patient[i]+'_'+N_slice[j]\n",
        " \n",
        "        in_name=os.path.join(base_dir,N_patient[i],N_slice[j])\n",
        "        out_name=os.path.join(base_dir,N_patient[i],Name)             \n",
        "        os.rename(in_name,out_name)\n",
        " \n",
        "        in_name1=os.path.join(base_dir1,N_patient[i],N_slice[j][:-4]+'.jpg')\n",
        "        out_name1=os.path.join(base_dir1,N_patient[i],Name[:-4]+'.jpg')           \n",
        "        os.rename(in_name1,out_name1)\n",
        " \n",
        "        shutil.move(out_name,home+'/train_labels')                                   \n",
        "        shutil.move(out_name1,home+'/train')\n",
        " \n",
        "for i in range(120,150):\n",
        "    N_slice=os.listdir(home + \"/ct_lesion_seg/mask/\" + N_patient[i])             \n",
        "    for j in range(0,len(N_slice)):\n",
        "        Name=N_patient[i]+'_'+N_slice[j]\n",
        " \n",
        "        in_name=os.path.join(base_dir,N_patient[i],N_slice[j])\n",
        "        out_name=os.path.join(base_dir,N_patient[i],Name)\n",
        "        os.rename(in_name,out_name)\n",
        " \n",
        "        in_name1=os.path.join(base_dir1,N_patient[i],N_slice[j][:-4]+'.jpg')\n",
        "        out_name1=os.path.join(base_dir1,N_patient[i],Name[:-4]+'.jpg')\n",
        "        os.rename(in_name1,out_name1)\n",
        " \n",
        "        shutil.move(out_name,home + '/test_labels') \n",
        "        shutil.move(out_name1,home + '/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "weDjF0b8gl0r",
        "outputId": "acdbf9c2-2507-4922-d03a-46d42a829047"
      },
      "source": [
        "list_os_train_masks = os.listdir(os.path.join(os.getcwd(),\"train_labels\"))\n",
        " \n",
        "counter_0 =0\n",
        "counter_1 =0\n",
        "counter_2 =0\n",
        "counter_3 =0\n",
        " \n",
        "for i in list_os_train_masks:\n",
        "    image = cv2.imread(os.path.join(os.getcwd(),\"train_labels\",i))\n",
        "    image = np.asarray(image)\n",
        "    values = np.unique(image, return_counts=True)\n",
        " \n",
        " \n",
        "    if len(values[0]) == 1:\n",
        "        counter_0 += values[1][0]\n",
        "    \n",
        "    if len(values[0]) == 2:\n",
        "        counter_0 += values[1][0]\n",
        "        counter_1 += values[1][1]\n",
        " \n",
        "    if len(values[0]) == 3:\n",
        "        counter_0 += values[1][0]\n",
        "        counter_1 += values[1][1]\n",
        "        counter_2 += values[1][2]\n",
        " \n",
        "    if len(values[0]) == 4:\n",
        "        counter_0 += values[1][0]\n",
        "        counter_1 += values[1][1]\n",
        "        counter_2 += values[1][2]\n",
        "        counter_3 += values[1][3]\n",
        " \n",
        " \n",
        "num_pixels = 512 * 512 * len(list_os_train_masks) * 3\n",
        "rate_0 = counter_0/num_pixels\n",
        "rate_1 = counter_1/num_pixels\n",
        "rate_2 = counter_2/num_pixels\n",
        "rate_3 = counter_3/num_pixels\n",
        " \n",
        " \n",
        " \n",
        "print(\"Rate 0:\",rate_0)\n",
        "print(\"Rate 1:\",rate_1)\n",
        "print(\"Rate 2:\",rate_2)\n",
        "print(\"Rate 3:\",rate_3)\n",
        " \n",
        "weights = [1-rate_0, 1 - rate_1, 1-rate_2, 1-rate_3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rate 0: 0.8737735939025879\n",
            "Rate 1: 0.1146315574645996\n",
            "Rate 2: 0.007890001932779948\n",
            "Rate 3: 0.0037048467000325522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M-X_SwKD7Uxm",
        "outputId": "f3e7fbce-6f85-4ba5-c19f-a43f4f29c8a8"
      },
      "source": [
        "home=os.getcwd()\n",
        "slices = os.listdir(home+\"/train\")\n",
        "first_chann=[]\n",
        "second_chann=[]\n",
        "third_chann=[]\n",
        "\n",
        "std_1=[]\n",
        "std_2=[]\n",
        "std_3=[]\n",
        "\n",
        "for i in range(0,len(slices)):\n",
        "    \n",
        "    np_image = np.array(cv2.imread(home+\"/train/\"+slices[i]))/255\n",
        "\n",
        "    \n",
        "    first_chann.append(np_image[:,:,0])\n",
        "    second_chann.append(np_image[:,:,1])\n",
        "    third_chann.append(np_image[:,:,2])\n",
        "\n",
        "\n",
        "first_chann = np.asarray(first_chann)\n",
        "second_chann = np.asarray(second_chann)\n",
        "third_chann = np.asarray(third_chann)\n",
        "   \n",
        "print(\"media primo canale: \", np.mean(first_chann), \"\\n dev st primo canale: \", np.std(first_chann))\n",
        "print(\"media secondo canale: \", np.mean(second_chann), \"\\n dev st seconda canale: \", np.std(second_chann))\n",
        "print(\"media terzo canale: \", np.mean(third_chann), \"\\n dev st terzo canale: \", np.std(third_chann))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "media primo canale:  0.527907796273825 \n",
            " dev st primo canale:  0.35843899808046975\n",
            "media secondo canale:  0.527907796273825 \n",
            " dev st seconda canale:  0.35843899808046975\n",
            "media terzo canale:  0.527907796273825 \n",
            " dev st terzo canale:  0.35843899808046975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fX4XLNTXsJ18"
      },
      "source": [
        "class COVIDDataSet(Dataset):\n",
        "    def __init__(self, root,  img_transform=None, mode=None):\n",
        "        self.root = root\n",
        "        self.img_transform = img_transform\n",
        "        \n",
        "        self.data_dir = root\n",
        "        self.mask_dir = root+\"_labels\"\n",
        "        self.img_list = os.listdir(self.data_dir)\n",
        "        self.mask_list = os.listdir(self.mask_dir)\n",
        "        self.mode = mode\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def backgElim(self, img, mask):\n",
        "\n",
        "        background = (mask > 0.5)*1\n",
        "        new_image = np.multiply(img, background)\n",
        "\n",
        "        return new_image\n",
        "\n",
        "\n",
        "    def transform(self, image, mask, mode=None):\n",
        "        \n",
        "\n",
        "        # Random crop\n",
        "        # print(image.shape)\n",
        "        image = torch.from_numpy(image)\n",
        "        mask = torch.from_numpy(mask)\n",
        "        # print(mask.shape)\n",
        "        image = image.permute(2,0,1)\n",
        "        # mask = image.permute(2,0,1)\n",
        "        mask = mask.view(1,512,512)\n",
        "        # print(image.shape)\n",
        "        # image = torchvision.transforms.ToPILImage(image)\n",
        "        # mask = torchvision.transforms.ToPILImage(mask)\n",
        "        if mode == 'train':\n",
        "          if random.random() > 0.5:\n",
        "              i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(256,256))\n",
        "              image = TF.crop(image, i, j, h, w)\n",
        "              mask = TF.crop(mask, i, j, h, w)\n",
        "\n",
        "\n",
        "          # Resize\n",
        "          resize = transforms.Resize(size=(512, 512))\n",
        "          image = resize(image)\n",
        "          mask = resize(mask)\n",
        "\n",
        "          # Random horizontal flipping\n",
        "          if random.random() > 0.5:\n",
        "              image = TF.hflip(image)\n",
        "              mask = TF.hflip(mask)\n",
        "\n",
        "          # Random vertical flipping\n",
        "          if random.random() > 0.5:\n",
        "              image = TF.vflip(image)\n",
        "              mask = TF.vflip(mask)\n",
        "\n",
        "        image = image.float()\n",
        "        image = TF.normalize(image,mean=[0.0501054,0.0501054,0.0501054],std=[0.1438656,0.1438656,0.1438656])\n",
        "\n",
        "        return image, mask\n",
        " \n",
        "    def __getitem__(self, index):\n",
        " \n",
        "        if self.img_transform == None:\n",
        "          imgs = cv2.imread(os.path.join(self.data_dir, self.img_list[index]))\n",
        "          new_index =  self.mask_list.index( self.img_list[index][:-4]+\".png\")\n",
        "          labels = cv2.imread(os.path.join(self.mask_dir, self.mask_list[new_index]))\n",
        "          imgs = self.backgElim(imgs,labels)\n",
        "\n",
        "          labels = cv2.cvtColor(labels, cv2.COLOR_BGR2GRAY)\n",
        "          im =os.path.join(self.data_dir, self.img_list[index])\n",
        "          mask = os.path.join(self.mask_dir, self.mask_list[new_index])\n",
        " \n",
        "        else:\n",
        "          imgs = cv2.imread(os.path.join(self.data_dir, self.img_list[index]))\n",
        "          new_index =  self.mask_list.index( self.img_list[index][:-4]+\".png\")\n",
        "          labels = cv2.imread(os.path.join(self.mask_dir, self.mask_list[new_index]))\n",
        "          imgs = self.backgElim(imgs,labels)\n",
        "          labels = cv2.cvtColor(labels, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "          im =os.path.join(self.data_dir, self.img_list[index])\n",
        "          mask = os.path.join(self.mask_dir, self.mask_list[new_index])\n",
        "          imgs, labels = self.transform(imgs,labels, self.mode)\n",
        " \n",
        "        return imgs, labels, im, mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-Zioozo-2M8A"
      },
      "source": [
        "trainsetCT__ = COVIDDataSet(root=train_img,\n",
        "                       img_transform= True, mode='train')\n",
        " \n",
        "valsetCT__ = COVIDDataSet(root=test_img,\n",
        "                     img_transform= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EkHzmM6y3AMU"
      },
      "source": [
        "train_loader = DataLoader(trainsetCT__, batch_size=cfg.batch_size, drop_last=False, shuffle=True)\n",
        "val_loader = DataLoader(valsetCT__, batch_size=cfg.batch_size, drop_last=True, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7gsVl9hVIQCj"
      },
      "source": [
        "#@title plotting for training\n",
        "class LinePlotter(object):\n",
        "    def __init__(self, env_name=\"main\"):\n",
        "        self.vis = visdom.Visdom(use_incoming_socket=False)\n",
        "        self.env = env_name\n",
        "        self.plots = {}\n",
        "\n",
        "    def plot(self, var_name, split_name, x, y):\n",
        "        if var_name not in self.plots:\n",
        "            self.plots[var_name] = self.vis.line(X=np.array([x, x]),\n",
        "                                    Y=np.array([y, y]), env=self.env, opts=dict(\n",
        "                                    legend=[split_name],\n",
        "                                    title=var_name,\n",
        "                                    xlabel=\"Iters\",\n",
        "                                    ylabel=var_name\n",
        "                                    ))\n",
        "        else:\n",
        "            self.vis.updateTrace(X=np.array([x, x]), Y=np.array([y, y]), env=self.env,\n",
        "                                win=self.plots[var_name], name=split_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4l9Y7JosJ4g"
      },
      "source": [
        " #@title visualize images from batch\n",
        " \n",
        "def imshow(img):\n",
        "#     img = img / 2 + 0.5     # unnormalize\n",
        "    print(\"Images:\",img.shape)\n",
        "    img = img.permute(1, 2, 0)\n",
        "    plt.figure(figsize = (20, 20))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        " \n",
        "def imshow_mask(img):\n",
        "    img = img * 50     # unnormalize\n",
        "    img = img.permute(1, 2, 0)\n",
        "    plt.figure(figsize = (20, 20))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    \n",
        "dataiter = iter(train_loader)\n",
        "images, labels_, im, masks_ = dataiter.next()\n",
        "images_p = images[:4]\n",
        "labels_p = labels_[:4]\n",
        "# images = images.permute(0,3,1,2)\n",
        "# labels_ = labels_.view(10,512,512,1)\n",
        "# labels_ = labels_.permute(0,3,1,2)\n",
        "print(labels_p.shape)\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "imshow_mask(torchvision.utils.make_grid(labels_))\n",
        "print(images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GTm3B13AGTc"
      },
      "source": [
        "#Function to make customized layers\n",
        "def make_layer(block, in_channels, channels, num_blocks, stride=1, dilation=1):\n",
        "    strides = [stride] + [1]*(num_blocks - 1)\n",
        "\n",
        "    blocks = []\n",
        "    for stride in strides:\n",
        "        blocks.append(block(in_channels=in_channels, channels=channels, stride=stride, dilation=dilation))\n",
        "        in_channels = block.expansion*channels\n",
        "\n",
        "    layer = nn.Sequential(*blocks)\n",
        "\n",
        "    return layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br8CiTGhAGQ6"
      },
      "source": [
        "#@title Basic Bloc aka traditional Resnet block\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, channels, stride=1, dilation=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        out_channels = self.expansion*channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        if (stride != 1) or (in_channels != out_channels):\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            self.downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            self.downsample = nn.Sequential()\n",
        "\n",
        "          \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        out = out + self.downsample(x) #downsample does a sequential exec in case of stride =1\n",
        "\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_qbkSFdAll4"
      },
      "source": [
        "#@title Bottle neck block -> same as Basic block with an extra Conv + bn layer\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, channels, stride=1, dilation=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        out_channels = self.expansion*channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        if (stride != 1) or (in_channels != out_channels):\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            self.downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            self.downsample = nn.Sequential()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out = out + self.downsample(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBUHZM-gsJ-B"
      },
      "source": [
        "#@title Resnets of deeplabV3 -> downsample part\n",
        "\n",
        "class ResNet_Bottleneck_OS16(nn.Module):\n",
        "    def __init__(self, num_layers):\n",
        "        super(ResNet_Bottleneck_OS16, self).__init__()\n",
        "\n",
        "        if num_layers == 50:\n",
        "            resnet = models.resnet50(pretrained=True)\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "            print (\"pretrained resnet, 50\")\n",
        "        elif num_layers == 101:\n",
        "            resnet = models.resnet101(pretrained=True)\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "            print (\"pretrained resnet, 101\")\n",
        "        elif num_layers == 152:\n",
        "            resnet = models.resnet152(pretrained=True)\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "        else:\n",
        "            raise Exception(\"num_layers must be in {50, 101, 152}!\")\n",
        "\n",
        "        self.layer5 = make_layer(Bottleneck, in_channels=4*256, channels=512, num_blocks=3, stride=1, dilation=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c4 = self.resnet(x)\n",
        "        output = self.layer5(c4)\n",
        "\n",
        "        return output\n",
        "\n",
        "class ResNet_BasicBlock_OS16(nn.Module):\n",
        "    def __init__(self, num_layers):\n",
        "        super(ResNet_BasicBlock_OS16, self).__init__()\n",
        "\n",
        "        if num_layers == 18:\n",
        "            resnet = models.resnet18(pretrained=True)\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "            num_blocks = 2\n",
        "            print (\"pretrained resnet, 18\")\n",
        "        elif num_layers == 34:\n",
        "            resnet = models.resnet34(pretrained=True)\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "            num_blocks = 3\n",
        "            print (\"pretrained resnet, 34\")\n",
        "        else:\n",
        "            raise Exception(\"num_layers must be in {18, 34}!\")\n",
        "\n",
        "        self.layer5 = make_layer(BasicBlock, in_channels=256, channels=512, num_blocks=num_blocks, stride=1, dilation=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c4 = self.resnet(x)\n",
        "        output = self.layer5(c4)\n",
        "\n",
        "        return output\n",
        "\n",
        "class ResNet_BasicBlock_OS8(nn.Module):\n",
        "    def __init__(self, num_layers):\n",
        "        super(ResNet_BasicBlock_OS8, self).__init__()\n",
        "\n",
        "        if num_layers == 18:\n",
        "            resnet = models.resnet18(pretrained=True)\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-4])\n",
        "            num_blocks_layer_4 = 2\n",
        "            num_blocks_layer_5 = 2\n",
        "            print (\"pretrained resnet, 18\")\n",
        "        elif num_layers == 34:\n",
        "            resnet = models.resnet34(pretrained=True)\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-4])\n",
        "            num_blocks_layer_4 = 6\n",
        "            num_blocks_layer_5 = 3\n",
        "            print (\"pretrained resnet, 34\")\n",
        "        else:\n",
        "            raise Exception(\"num_layers must be in {18, 34}!\")\n",
        "\n",
        "        self.layer4 = make_layer(BasicBlock, in_channels=128, channels=256, num_blocks=num_blocks_layer_4, stride=1, dilation=2)\n",
        "\n",
        "        self.layer5 = make_layer(BasicBlock, in_channels=256, channels=512, num_blocks=num_blocks_layer_5, stride=1, dilation=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c3 = self.resnet(x)\n",
        "\n",
        "        output = self.layer4(c3)\n",
        "        output = self.layer5(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw5sT0AYGZ5I"
      },
      "source": [
        "def ResNet50_OS16():\n",
        "    return ResNet_Bottleneck_OS16(num_layers=50)\n",
        "\n",
        "def ResNet50_OS8():\n",
        "    return ResNet_BasicBlock_OS16(num_layers=18)\n",
        "\n",
        "def ResNet101_OS16():\n",
        "    return ResNet_Bottleneck_OS16(num_layers=101)\n",
        "\n",
        "def ResNet152_OS16():\n",
        "    return ResNet_Bottleneck_OS16(num_layers=152)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLTaR2-pql5E"
      },
      "source": [
        "#@title Upsample\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ASPP, self).__init__()\n",
        "\n",
        "        self.conv_1x1_1 = nn.Conv2d(512, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_1 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=6, dilation=6)\n",
        "        self.bn_conv_3x3_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_2 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=12, dilation=12)\n",
        "        self.bn_conv_3x3_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_3 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=18, dilation=18)\n",
        "        self.bn_conv_3x3_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.conv_1x1_2 = nn.Conv2d(512, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_1x1_3 = nn.Conv2d(1280, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_1x1_4 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, feature_map):\n",
        "        feature_map_h = feature_map.size()[2]\n",
        "        feature_map_w = feature_map.size()[3]\n",
        "\n",
        "        out_1x1 = F.relu(self.bn_conv_1x1_1(self.conv_1x1_1(feature_map)))\n",
        "        out_3x3_1 = F.relu(self.bn_conv_3x3_1(self.conv_3x3_1(feature_map)))\n",
        "        out_3x3_2 = F.relu(self.bn_conv_3x3_2(self.conv_3x3_2(feature_map)))\n",
        "        out_3x3_3 = F.relu(self.bn_conv_3x3_3(self.conv_3x3_3(feature_map)))\n",
        "\n",
        "        out_img = self.avg_pool(feature_map)\n",
        "        out_img = F.relu(self.bn_conv_1x1_2(self.conv_1x1_2(out_img)))\n",
        "        out_img = F.upsample(out_img, size=(feature_map_h, feature_map_w), mode=\"bilinear\")\n",
        "\n",
        "        out = torch.cat([out_1x1, out_3x3_1, out_3x3_2, out_3x3_3, out_img], 1)\n",
        "        out = F.relu(self.bn_conv_1x1_3(self.conv_1x1_3(out)))\n",
        "        out = self.conv_1x1_4(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ASPP_Bottleneck(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ASPP_Bottleneck, self).__init__()\n",
        "\n",
        "        self.conv_1x1_1 = nn.Conv2d(4*512, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_1 = nn.Conv2d(4*512, 256, kernel_size=3, stride=1, padding=6, dilation=6)\n",
        "        self.bn_conv_3x3_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_2 = nn.Conv2d(4*512, 256, kernel_size=3, stride=1, padding=12, dilation=12)\n",
        "        self.bn_conv_3x3_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_3 = nn.Conv2d(4*512, 256, kernel_size=3, stride=1, padding=18, dilation=18)\n",
        "        self.bn_conv_3x3_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.conv_1x1_2 = nn.Conv2d(4*512, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_1x1_3 = nn.Conv2d(1280, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_1x1_4 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, feature_map):\n",
        "        feature_map_h = feature_map.size()[2]\n",
        "        feature_map_w = feature_map.size()[3]\n",
        "\n",
        "        out_1x1 = F.relu(self.bn_conv_1x1_1(self.conv_1x1_1(feature_map)))\n",
        "        out_3x3_1 = F.relu(self.bn_conv_3x3_1(self.conv_3x3_1(feature_map)))\n",
        "        out_3x3_2 = F.relu(self.bn_conv_3x3_2(self.conv_3x3_2(feature_map)))\n",
        "        out_3x3_3 = F.relu(self.bn_conv_3x3_3(self.conv_3x3_3(feature_map)))\n",
        "\n",
        "        out_img = self.avg_pool(feature_map)\n",
        "        out_img = F.relu(self.bn_conv_1x1_2(self.conv_1x1_2(out_img)))\n",
        "        out_img = F.upsample(out_img, size=(feature_map_h, feature_map_w), mode=\"bilinear\")\n",
        "\n",
        "        out = torch.cat([out_1x1, out_3x3_1, out_3x3_2, out_3x3_3, out_img], 1)\n",
        "        out = F.relu(self.bn_conv_1x1_3(self.conv_1x1_3(out)))\n",
        "        out = self.conv_1x1_4(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw04QrKLql77"
      },
      "source": [
        "class DeepLabV3(nn.Module):\n",
        "    def __init__(self, n_channels = 3, n_classes = 4):\n",
        "        super(DeepLabV3, self).__init__()\n",
        "        self.resnet = ResNet50_OS16()\n",
        "        # self.resnet = ResNet50_OS8()\n",
        "        self.aspp = ASPP_Bottleneck(num_classes=n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        h = x.size()[2]\n",
        "        w = x.size()[3]\n",
        "\n",
        "        feature_map = self.resnet(x)\n",
        "\n",
        "        output = self.aspp(feature_map)\n",
        "\n",
        "        output = F.upsample(output, size=(h, w), mode=\"bilinear\")\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7yDdGypqmBk"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  model = DeepLabV3()\n",
        "  model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnB0z4xh2nYh"
      },
      "source": [
        "# for name, param in model.named_parameters():\n",
        "#     if \"resnet.resnet\" in name or \"layer4\" in name:\n",
        "#         param.requires_grad = False\n",
        "    # print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liHkJHqJqmEW"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor(weights))\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=cfg.lr, momentum=cfg.moemntum,\n",
        "                            weight_decay=2e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
        "#plotter = LinePlotter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "PVGZk98gqmKT"
      },
      "source": [
        "#@title training \n",
        "# if True:\n",
        "#     model.train()\n",
        "#     for epoch in range(cfg.n_epochs):\n",
        "#         running_loss = 0.0\n",
        "#         for i, (images, labels_group,im, masks ) in enumerate(train_loader):\n",
        "#             if torch.cuda.is_available():\n",
        "#                 images = images.float()\n",
        "#                 images = images.cuda()\n",
        "#                 labels_group = labels_group.long()\n",
        "#                 labels_group = labels_group.cuda()\n",
        "#             else:\n",
        "#                 continue\n",
        "    \n",
        "#             optimizer.zero_grad()\n",
        "#             losses = []\n",
        "#             # images = images.permute(0,3,1,2)\n",
        "#             # print(images.shape)\n",
        "#             output = model(images)\n",
        "#             # print(\"Labels:\",labels_group.shape)\n",
        "#             labels_group = labels_group.view(cfg.batch_size,512,512)\n",
        "#             loss = criterion(output.cuda(), labels_group.cuda())\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             running_loss += loss.item()\n",
        "    \n",
        "#             # lr = lr * (1-(92*epoch+i)/max_iters)**0.9\n",
        "#             # for parameters in optimizer.param_groups:\n",
        "#             #     parameters['lr'] = lr\n",
        "    \n",
        "#         print(\"Epoch [%d] Loss: %.4f\" % (epoch+1, running_loss/i))\n",
        "    \n",
        "#         if (epoch+1) %2 ==0:\n",
        "#             with torch.no_grad():\n",
        "#                 val_loss = 0.0\n",
        "#                 for i, (images, labels_group, im, masks) in enumerate(val_loader):\n",
        "#                     images = images.float()\n",
        "#                     images = images.cuda()\n",
        "#                     labels_group = labels_group.long()\n",
        "#                     labels_group = labels_group.cuda()\n",
        "        \n",
        "#                     images = images.permute(0,3,1,2)\n",
        "#                     output = model(images)\n",
        "#                     loss = criterion(output.cuda(), labels_group.cuda())\n",
        "#                     val_loss+=loss\n",
        "#                 print(\"Epoch [%d] Val_Loss: %.4f\" % (epoch+1, val_loss/i))\n",
        "    \n",
        "#         # ploter.plot(\"loss\", \"train\", epoch+1, running_loss/i)\n",
        "#         # running_loss = 0\n",
        "    \n",
        "#         # if (epoch+1) % 4 == 0:\n",
        "#         #     cfg.lr /= 10\n",
        "#         #     optimizer = torch.optim.SGD(model.parameters())\n",
        "#         #     torch.save(model.state_dict(), \"./pth/fcn-deconv-%d.pth\" % (epoch+1))\n",
        "\n",
        " \n",
        " \n",
        "# torch.save(model.state_dict(), \"./pth/fcn-deconv.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_DXD_09Cvag"
      },
      "source": [
        "def load_weight_from_parallel(PATH:str):\n",
        "  \"\"\"\n",
        "  input: PATH -> Path to trained model\n",
        "\n",
        "  function: nn.Dataparallel models saves the dict_states as modules, meanwhile normal models saves them without modules\n",
        "            so we want to remove the \"module.\" part from the keys of the dictionary\n",
        "\n",
        "  output: new dictionary with renamed keys\n",
        "  \"\"\"\n",
        "  parallel_weights = torch.load(PATH)\n",
        "  p_weights = dict(parallel_weights)\n",
        "  keys = [k for k in p_weights.keys()]\n",
        "  new_weights ={}\n",
        "  for key in keys:\n",
        "    new_weights[key[7:]] = p_weights[key]\n",
        "\n",
        "  return new_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ijhEr17CvWS"
      },
      "source": [
        "weights = load_weight_from_parallel('/content/drive/MyDrive/COV_SEG_MODEL/segnet_norm.pth')\n",
        "model.load_state_dict(weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MnVLE8ZH9IR"
      },
      "source": [
        "def test_analyticaly(model, val_loader):\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    val_loss = 0.0\n",
        "    for i, (images, labels_group, im, masks) in enumerate(val_loader):\n",
        "      images = images.float()\n",
        "      images = images.cuda()\n",
        "      labels_group = labels_group.long()\n",
        "      labels_group = labels_group.cuda()\n",
        "      labels_group = labels_group.view(cfg.batch_size,512,512)\n",
        "      # images = images.permute(0,3,1,2)\n",
        "      output = model(images)\n",
        "      loss = criterion(output.cuda(), labels_group.cuda())\n",
        "      val_loss+=loss\n",
        "      # print(type(val_loss))\n",
        "    print(\" Val_Loss: %.4f\" % (val_loss/i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHhlrEfLNNiL"
      },
      "source": [
        "test_analyticaly(model, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrvKhw93jzVb"
      },
      "source": [
        "dataiter = iter(val_loader)\n",
        "images, labels_, im, masks_ = dataiter.next()\n",
        "images_p = images[1]\n",
        "labels_p = labels_[1]\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "images_p = images_p.permute(1,2,0)\n",
        "plt.imshow(images_p)\n",
        "print(images_p.shape)\n",
        "plt.figure(figsize=(5,5))\n",
        "# labels_p = labels_p.permute(1,2,0)\n",
        "labels_p = labels_p.view(512,512)\n",
        "plt.imshow(labels_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Daf40kVxmay_"
      },
      "source": [
        "model.eval()\n",
        "images_p = images_p.permute(2,0,1)\n",
        "images_p = images_p.view(1,3,512,512).float()\n",
        "output = model(images_p.cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2069BN_ma3i"
      },
      "source": [
        "output_mask = torch.argmax(output.squeeze(), dim=0).detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MUTcn8Dma9M"
      },
      "source": [
        "print(np.unique(output_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRbNdQVuma1c"
      },
      "source": [
        "label_colors = np.array([(0,0,0),(128,0,0),(0,128,0), (0,0,128)])\n",
        "r = np.zeros_like(output_mask).astype(np.uint8)\n",
        "g = np.zeros_like(output_mask).astype(np.uint8)\n",
        "b = np.zeros_like(output_mask).astype(np.uint8)\n",
        "\n",
        "for l in range(0, 4):\n",
        "  idx = output_mask == l\n",
        "  r[idx] = label_colors[l, 0]\n",
        "  g[idx] = label_colors[l, 1]\n",
        "  b[idx] = label_colors[l, 2]\n",
        "\n",
        "rgb = np.stack([r, g, b], axis=2)\n",
        "plt.imshow(rgb)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfcXX5cFop3t"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(labels_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWsdC30rop6D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQD8S94Kop9F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjCRh-3EoqBQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSmYt2BYoqEZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv3NmseeoqAI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}